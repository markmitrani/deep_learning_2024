{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:49.282317600Z",
     "start_time": "2024-12-03T02:11:45.850318800Z"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install wget\n",
    "#%pip install torch\n",
    "import data_rnn\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.244317900Z",
     "start_time": "2024-12-03T02:11:49.283317300Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = data_rnn.load_imdb(final=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Classification: data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.260319100Z",
     "start_time": "2024-12-03T02:11:50.247318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([14, 19, 9, 379, 22, 11, 50, 52, 53, 290], 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0] # 0 is positive, 1 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.319323900Z",
     "start_time": "2024-12-03T02:11:50.262319200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99430"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i2w[word] for word in x_train[0]] # what is vocab?\n",
    "len(i2w) # what is vocab size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.329318Z",
     "start_time": "2024-12-03T02:11:50.278319100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2514 240.6318\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(l) for l in x_train]\n",
    "print(np.min(lengths), np.max(lengths), np.average(lengths)) # stats on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.330325200Z",
     "start_time": "2024-12-03T02:11:50.308316900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i['.pad'], w2i['.start'], w2i['.end'], w2i['.unk'] # special tokens and their ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Padding and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.341318800Z",
     "start_time": "2024-12-03T02:11:50.324318400Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining a pad  function\n",
    "def pad(seq, pad_length):\n",
    "    padded = np.zeros(pad_length) # 0 is for padding\n",
    "    padded[0:len(seq)] = seq\n",
    "    return torch.tensor(padded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.404317200Z",
     "start_time": "2024-12-03T02:11:50.338321400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad(x_train[0], 12).reshape(1,-1)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Classification, baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:16:47.311236200Z",
     "start_time": "2024-12-03T02:16:47.294237200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a tensor x, and return max across time dimension\n",
    "def MaxPoolTime(x):\n",
    "    return torch.amax(x, dim=1)\n",
    "\n",
    "class MlpModel(torch.nn.Module):\n",
    "    def __init__(self, batch_size=1):\n",
    "        super().__init__()\n",
    "        timestep = 12\n",
    "        numcls = 2\n",
    "        hidden = 300\n",
    "        embedding_size = 300\n",
    "        n_embeddings = len(i2w)\n",
    "        self.emb = torch.nn.Embedding(n_embeddings, embedding_size, padding_idx=0)\n",
    "        self.fc1 = torch.nn.Linear(embedding_size, hidden)\n",
    "        self.fc2 = torch.nn.Linear(hidden, numcls)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = MaxPoolTime(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.791317200Z",
     "start_time": "2024-12-03T02:11:50.417318200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\AppData\\Local\\Temp\\ipykernel_31972\\32988193.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.nn.functional.softmax(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3995, 0.6005]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick test\n",
    "baseline_model = MlpModel()\n",
    "y = baseline_model.forward(padded)\n",
    "torch.nn.functional.softmax(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:51.780348200Z",
     "start_time": "2024-12-03T02:11:50.789317800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pad all\n",
    "padding_size = np.max(lengths) # how big should the padding be? --> max seq length\n",
    "\n",
    "# pad train and validation set\n",
    "padded_train = torch.stack([pad(x, padding_size) for x in x_train])\n",
    "padded_val = torch.stack([pad(x, padding_size) for x in x_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 2514])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train.shape # check shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and validation datalaoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:51.796336800Z",
     "start_time": "2024-12-03T02:11:51.782318700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "# set to device\n",
    "padded_train = padded_train.to(device)\n",
    "padded_val = padded_val.to(device)\n",
    "y_train_tensor = torch.tensor(y_train).to(device)\n",
    "y_val_tensor = torch.tensor(y_val).to(device)\n",
    "\n",
    "# create train and val datasets with instance and label pairs\n",
    "train_dataset = TensorDataset(padded_train, torch.tensor(y_train))\n",
    "validation_dataset = TensorDataset(padded_val, torch.tensor(y_val))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validation_loader):\n",
    "    val_acc = 0\n",
    "    val_correct = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            instances, labels = data\n",
    "            fwd = model(instances)\n",
    "            predictions = torch.argmax(fwd, dim=1)\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Compute and return accuracy\n",
    "    val_acc = val_correct / total_samples\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:21:46.634744200Z",
     "start_time": "2024-12-03T02:16:51.509394100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, testloader, optimizer, nr_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(nr_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "            instances, labels = batch\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(instances)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % len(trainloader)/len(batch)*2 == 0:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "                running_loss = 0.0\n",
    "        val_acc = validate(model, testloader)\n",
    "        print(f'Epoch {epoch}, validation acc.: {val_acc}')\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\n",
    "baseline_model = MlpModel(batch_size).to(device)\n",
    "final_model = train_model(baseline_model, trainloader, testloader, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Writing your own Elman RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only answers \"complete the missing parts\" question. The full implementation on the dataset is in q4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elman(torch.nn.Module):\n",
    "    def __init__(self, insize=300, outsize=300, hsize=300):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(insize+hsize, hsize)\n",
    "        self.lin2 = torch.nn.Linear(hsize, outsize)\n",
    "\n",
    "    def forward(self, x, hidden=None): \n",
    "        '''\n",
    "        b: batch size\n",
    "        t: time steps (ie. sequence length)\n",
    "        e: dimension of each input vector\n",
    "        '''\n",
    "\n",
    "        b, t, e = x.size() \n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(b, e, dtype=torch.float) #make a tensor of inputs (bxe) \n",
    "            \n",
    "        outs = []\n",
    "        for i in range(t): #iterate through each value of the sequence\n",
    "            inp = torch.cat([x[:, i, :], hidden], dim=1) #take only the value being iterated \n",
    "            inp = self.lin1(inp)\n",
    "            hidden = torch.nn.functional.sigmoid(inp)\n",
    "            out = self.lin2(hidden)\n",
    "            outs.append(out[:, None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ElmanModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self).__init__()\n",
    "        hidden = 300\n",
    "        embedding_size = 300\n",
    "        num_classes = 2\n",
    "        vocab_size = len(i2w)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        self.fc1 = Elman(embedding_size, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x[0])\n",
    "        x = torch.amax(x, dim=1)  # Max pooling across the time dimension\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from question5.hypertuning import main as run_hypertuning\n",
    "run_hypertuning()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Autoregressive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, (i2w, w2i) = data_rnn.load_ndfa(n=150_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, (i2w, w2i) = data_rnn.load_brackets(n=150_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 4],\n",
       " ['.pad', '.start', '.end', '.unk', ')', '('],\n",
       " {'.pad': 0, '.start': 1, '.end': 2, '.unk': 3, ')': 4, '(': 5},\n",
       " 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], i2w, w2i, len(i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', '(', ')', ')']\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [i2w[x] for x in x_train[100_000-2]]\n",
    "print(seq)\n",
    "print(len(seq))\n",
    "16-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding for the autoregressive task\n",
    "def pad_ar(seq, pad_length):\n",
    "    assert len(seq) <= pad_length-2, f\"pad length {pad_length} too short for sequence of length {len(seq)}\"\n",
    "\n",
    "    padded = np.zeros(pad_length) # 0 is for '.pad'\n",
    "    padded[0] = 1 # 1 is for '.start'\n",
    "    padded[1:len(seq)+1] = seq # insert sequence\n",
    "    padded[len(seq)+1] = 2 # 2 is for '.end'\n",
    "    \n",
    "    return torch.tensor(padded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 4, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 5, 4, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train[100_000-2])\n",
    "pad_ar(x_train[100_000-2], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(2), np.float64(9.01628), np.int64(1022))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(x) for x in x_train]\n",
    "np.min(lengths), np.average(lengths), np.max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_size = np.max(lengths)+2 # accounts for start and end tokens\n",
    "padded_train = torch.stack([pad_ar(x, padding_size) for x in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1024])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_train), padded_train.shape\n",
    "padded_train[0:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150000, 159])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train[:, 1:160].shape\n",
    "# torch.select(padded_train, 1, 1:-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifts tensor values by 1 to the left\n",
    "def create_target(tensor):\n",
    "    shifted = tensor[:, 1:tensor.shape[1]]\n",
    "    shifted = torch.cat((shifted, torch.zeros((shifted.shape[0], 1))), dim=1)\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_test = create_target(padded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train[0].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assert(all(padded_train[:,-1]) == 0)\n",
    "max(padded_train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the last entry in shifted is always 0\n",
    "torch.unique(padded_test[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cat((shifted, torch.zeros(shifted.shape[0]).reshape(1,-1)), dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the train and target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARModel(torch.nn.Module):\n",
    "    def __init__(self, batch_size=1, e = 32, h = 16):\n",
    "        super().__init__()\n",
    "        num_chars = len(i2w) # num chars given by i2w\n",
    "        embedding_size = 32\n",
    "        hidden = 16\n",
    "        n_embeddings = len(i2w)\n",
    "        self.emb = torch.nn.Embedding(num_chars, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size=hidden,\n",
    "                            num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden, num_chars)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e = self.emb(x)\n",
    "        #print(f\"e {type(e)} shape: {e.shape}\")\n",
    "        h = self.lstm(e)[0]\n",
    "        #print(f\"h {type(h)} shape: {h.shape}\")\n",
    "        y = self.fc1(h)\n",
    "        #print(f\"y {type(y)} shape: {y.shape}\")\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# set to device\n",
    "padded_x = padded_train.to(device)\n",
    "padded_y = padded_test.to(device)\n",
    "\n",
    "# create train dataset with instance and label pairs\n",
    "train_dataset = TensorDataset(padded_x, padded_y)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, optimizer, nr_epochs = 3):\n",
    "    for epoch in range(nr_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "            instances, targets = batch\n",
    "            targets = targets.long()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(instances)\n",
    "            outputs = torch.transpose(outputs, 1, 2)\n",
    "            #print(f'outputs: {outputs.shape}')\n",
    "            #print(f'targets: {targets.shape}')\n",
    "            #print(outputs.dtype)\n",
    "            #print(targets.dtype)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, targets, reduction='sum')#/len(instances)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, loss: {running_loss/len(trainloader)}\")\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m q6model \u001b[38;5;241m=\u001b[39m ARModel(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(q6model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m final_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq6model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, trainloader, optimizer, nr_epochs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nr_epochs):\n\u001b[0;32m      3\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "q6model = ARModel(batch_size=32).to(device)\n",
    "optimizer = optim.Adam(q6model.parameters(), lr=0.001)\n",
    "final_model = train_model(q6model, trainloader, optimizer, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "def sample(lnprobs, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample an element from a categorical distribution\n",
    "    :param lnprobs: Outcome logits\n",
    "    :param temperature: Sampling temperature. 1.0 follows the given\n",
    "    distribution, 0.0 returns the maximum probability element.\n",
    "    :return: The index of the sampled element.\n",
    "    \"\"\"\n",
    "    if temperature == 0.0:\n",
    "        return lnprobs.argmax()\n",
    "    p = torch.nn.functional.softmax(lnprobs / temperature, dim=1)\n",
    "    cd = dist.Categorical(p)\n",
    "    return cd.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [w2i['.start'], w2i['('], w2i['('], w2i[')']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_sequence(seq, model, temp = 0.5, max_len = 25):\n",
    "    generated = seq.copy()\n",
    "    seq_tensor = torch.tensor(generated).reshape(1,-1).to(device)\n",
    "    for i in range(max_len):\n",
    "        next_index = sample(model(seq_tensor).select(dim=1, index=-1), temp)\n",
    "        next_char = i2w[next_index]\n",
    "        if next_char == '.end':\n",
    "            print(next_char)\n",
    "            break\n",
    "        else:\n",
    "            print(next_char)\n",
    "            generated.append(next_index)\n",
    "            seq_tensor = torch.tensor(generated).reshape(1,-1).to(device)\n",
    "            \n",
    "    # correctness check\n",
    "    generated_chars = [i2w[idx] for idx in generated]\n",
    "    left = generated_chars.count(\"(\")\n",
    "    right = generated_chars.count(\")\")\n",
    "    print(f\"left {left}, right {right}\")\n",
    "\n",
    "    return True if left==right else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [w2i['.start'], w2i['('], w2i['('], w2i[')']]\n",
    "complete_sequence(seq, final_model, temp=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_sampling(model, trainloader, optimizer, seq, temp = 0.5, nr_epochs = 3):\n",
    "    for epoch in range(nr_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "            instances, targets = batch\n",
    "            targets = targets.long()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(instances)\n",
    "            outputs = torch.transpose(outputs, 1, 2)\n",
    "            #print(f'outputs: {outputs.shape}')\n",
    "            #print(f'targets: {targets.shape}')\n",
    "            #print(outputs.dtype)\n",
    "            #print(targets.dtype)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, targets, reduction='sum')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, loss: {running_loss/len(trainloader)}\")\n",
    "        for j in range(10):\n",
    "            print(f\"Completion of sequence (E{epoch}S{j}):\")\n",
    "            complete_sequence(seq, model)\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 420.47772384666337\n",
      "Completion of sequence (E0S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E0S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E0S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E0S3):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 5, right 5\n",
      "Completion of sequence (E0S4):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 5, right 5\n",
      "Completion of sequence (E0S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E0S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E0S7):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E0S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E0S9):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Epoch 2, loss: 176.77880371471315\n",
      "Completion of sequence (E1S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E1S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E1S2):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E1S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E1S4):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E1S5):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E1S6):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E1S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E1S8):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E1S9):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Epoch 3, loss: 176.0817202048904\n",
      "Completion of sequence (E2S0):\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "left 18, right 10\n",
      "Completion of sequence (E2S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E2S2):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E2S3):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E2S4):\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 9, right 9\n",
      "Completion of sequence (E2S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E2S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E2S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E2S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E2S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 4, loss: 175.99913592956986\n",
      "Completion of sequence (E3S0):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 7, right 7\n",
      "Completion of sequence (E3S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E3S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E3S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E3S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E3S5):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E3S6):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E3S7):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E3S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E3S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 5, loss: 175.96252124871003\n",
      "Completion of sequence (E4S0):\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 7, right 7\n",
      "Completion of sequence (E4S1):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 12, right 12\n",
      "Completion of sequence (E4S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E4S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E4S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E4S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E4S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E4S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E4S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E4S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 6, loss: 175.9618805219696\n",
      "Completion of sequence (E5S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E5S1):\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 6, right 6\n",
      "Completion of sequence (E5S2):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E5S3):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 5, right 5\n",
      "Completion of sequence (E5S4):\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      "left 14, right 14\n",
      "Completion of sequence (E5S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E5S6):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E5S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E5S8):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 7, right 7\n",
      "Completion of sequence (E5S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 7, loss: 175.95548886976144\n",
      "Completion of sequence (E6S0):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E6S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E6S2):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E6S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E6S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E6S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E6S6):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 11, right 11\n",
      "Completion of sequence (E6S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E6S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E6S9):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 6, right 6\n",
      "Epoch 8, loss: 175.95151084519082\n",
      "Completion of sequence (E7S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E7S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 9, loss: 175.94237823697895\n",
      "Completion of sequence (E8S0):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E8S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E8S2):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E8S3):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 6, right 6\n",
      "Completion of sequence (E8S4):\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 7, right 7\n",
      "Completion of sequence (E8S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E8S6):\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 12, right 12\n",
      "Completion of sequence (E8S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E8S8):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E8S9):\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 12, right 12\n",
      "Epoch 10, loss: 175.95279936823016\n",
      "Completion of sequence (E9S0):\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 11, right 11\n",
      "Completion of sequence (E9S1):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 11, right 11\n",
      "Completion of sequence (E9S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E9S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E9S4):\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 8, right 8\n",
      "Completion of sequence (E9S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E9S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E9S7):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E9S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E9S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 11, loss: 175.94379211936794\n",
      "Completion of sequence (E10S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E10S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E10S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E10S3):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E10S4):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E10S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E10S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E10S7):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E10S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E10S9):\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 5, right 5\n",
      "Epoch 12, loss: 175.94641101970606\n",
      "Completion of sequence (E11S0):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 7, right 7\n",
      "Completion of sequence (E11S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E11S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E11S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E11S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E11S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E11S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E11S7):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E11S8):\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "left 17, right 11\n",
      "Completion of sequence (E11S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 13, loss: 175.9349814746974\n",
      "Completion of sequence (E12S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E12S1):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E12S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E12S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E12S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E12S5):\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "left 15, right 13\n",
      "Completion of sequence (E12S6):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E12S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E12S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E12S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 14, loss: 175.95106476565678\n",
      "Completion of sequence (E13S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E13S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E13S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E13S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E13S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E13S5):\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 6, right 6\n",
      "Completion of sequence (E13S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E13S7):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E13S8):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 6, right 6\n",
      "Completion of sequence (E13S9):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Epoch 15, loss: 175.9526921197416\n",
      "Completion of sequence (E14S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E14S1):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 6, right 6\n",
      "Completion of sequence (E14S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E14S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E14S4):\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "left 15, right 13\n",
      "Completion of sequence (E14S5):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      "left 17, right 11\n",
      "Completion of sequence (E14S6):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "left 17, right 11\n",
      "Completion of sequence (E14S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E14S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E14S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 16, loss: 175.94785006705405\n",
      "Completion of sequence (E15S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E15S1):\n",
      "(\n",
      ")\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      "left 16, right 12\n",
      "Completion of sequence (E15S2):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 8, right 8\n",
      "Completion of sequence (E15S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E15S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E15S5):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E15S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E15S7):\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 4, right 4\n",
      "Completion of sequence (E15S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E15S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 17, loss: 175.93338432735143\n",
      "Completion of sequence (E16S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E16S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 18, loss: 175.95414306360706\n",
      "Completion of sequence (E17S0):\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 8, right 8\n",
      "Completion of sequence (E17S1):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E17S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E17S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E17S4):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E17S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E17S6):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E17S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E17S8):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E17S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 19, loss: 175.940978804546\n",
      "Completion of sequence (E18S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E18S1):\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 7, right 7\n",
      "Completion of sequence (E18S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E18S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E18S4):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E18S5):\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 5, right 5\n",
      "Completion of sequence (E18S6):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E18S7):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E18S8):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E18S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Epoch 20, loss: 175.95400728910857\n",
      "Completion of sequence (E19S0):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E19S1):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E19S2):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E19S3):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E19S4):\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 5, right 5\n",
      "Completion of sequence (E19S5):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E19S6):\n",
      "(\n",
      "(\n",
      "(\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      "(\n",
      ")\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 7, right 7\n",
      "Completion of sequence (E19S7):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Completion of sequence (E19S8):\n",
      "(\n",
      ")\n",
      ")\n",
      ".end\n",
      "left 3, right 3\n",
      "Completion of sequence (E19S9):\n",
      ")\n",
      ".end\n",
      "left 2, right 2\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "seq = [w2i['.start'], w2i['('], w2i['('], w2i[')']]\n",
    "q6model = ARModel(batch_size=1).to(device)\n",
    "optimizer = optim.Adam(q6model.parameters(), lr=0.003)\n",
    "final_model = train_model_sampling(q6model, trainloader, optimizer, seq, 0.25, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
