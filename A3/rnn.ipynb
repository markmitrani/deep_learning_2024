{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:49.282317600Z",
     "start_time": "2024-12-03T02:11:45.850318800Z"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install wget\n",
    "#%pip install torch\n",
    "import data_rnn\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.244317900Z",
     "start_time": "2024-12-03T02:11:49.283317300Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = data_rnn.load_imdb(final=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Classification: data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.260319100Z",
     "start_time": "2024-12-03T02:11:50.247318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([14, 19, 9, 379, 22, 11, 50, 52, 53, 290], 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0] # 0 is positive, 1 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.319323900Z",
     "start_time": "2024-12-03T02:11:50.262319200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99430"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i2w[word] for word in x_train[0]]\n",
    "len(i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.329318Z",
     "start_time": "2024-12-03T02:11:50.278319100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2514 240.6318\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(l) for l in x_train]\n",
    "print(np.min(lengths), np.max(lengths), np.average(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.330325200Z",
     "start_time": "2024-12-03T02:11:50.308316900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i['.pad'], w2i['.start'], w2i['.end'], w2i['.unk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Padding and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.341318800Z",
     "start_time": "2024-12-03T02:11:50.324318400Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad(seq, pad_length):\n",
    "    padded = np.zeros(pad_length) # 0 is for padding\n",
    "    padded[0:len(seq)] = seq\n",
    "    return torch.tensor(padded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.404317200Z",
     "start_time": "2024-12-03T02:11:50.338321400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad(x_train[0], 12).reshape(1,-1)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Classification, baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:16:47.311236200Z",
     "start_time": "2024-12-03T02:16:47.294237200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a tensor x, and return max across time dimension\n",
    "def MaxPoolTime(x):\n",
    "    return torch.amax(x, dim=1)\n",
    "\n",
    "class q2_baseline(torch.nn.Module):\n",
    "    def __init__(self, batch_size=1):\n",
    "        super().__init__()\n",
    "        timestep = 12\n",
    "        numcls = 2\n",
    "        hidden = 300\n",
    "        embedding_size = 300\n",
    "        n_embeddings = len(i2w)\n",
    "        self.emb = torch.nn.Embedding(n_embeddings, embedding_size, padding_idx=0)\n",
    "        self.fc1 = torch.nn.Linear(embedding_size, hidden)\n",
    "        self.fc2 = torch.nn.Linear(hidden, numcls)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = MaxPoolTime(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:50.791317200Z",
     "start_time": "2024-12-03T02:11:50.417318200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/n1g26qmn72ldwxh52bkgncv40000gn/T/ipykernel_17660/3313671974.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.nn.functional.softmax(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5154, 0.4846]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = q2_baseline()\n",
    "y = baseline_model.forward(padded)\n",
    "torch.nn.functional.softmax(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:51.780348200Z",
     "start_time": "2024-12-03T02:11:50.789317800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pad all\n",
    "padding_size = np.max(lengths)\n",
    "\n",
    "padded_train = torch.stack([pad(x, padding_size) for x in x_train])\n",
    "padded_val = torch.stack([pad(x, padding_size) for x in x_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 2514])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:11:51.796336800Z",
     "start_time": "2024-12-03T02:11:51.782318700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# create train and val datasets with instance and label pairs\n",
    "train_dataset = TensorDataset(padded_train, torch.tensor(y_train))\n",
    "validation_dataset = TensorDataset(padded_val, torch.tensor(y_val))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:14:21.252226800Z",
     "start_time": "2024-12-03T02:14:19.666841100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# setup training loop\n",
    "\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validation_loader):\n",
    "    val_acc = 0\n",
    "    val_correct = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            instances, labels = data\n",
    "            fwd = model(instances)\n",
    "            predictions = torch.argmax(fwd, dim=1)\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Compute and return accuracy\n",
    "    val_acc = val_correct / total_samples\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:21:46.634744200Z",
     "start_time": "2024-12-03T02:16:51.509394100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.713\n",
      "[1,   400] loss: 0.708\n",
      "[1,   600] loss: 0.713\n",
      "Epoch 0, validation acc.: 0.4926\n",
      "[2,   200] loss: 0.714\n"
     ]
    }
   ],
   "source": [
    "baseline_model = q2_baseline(batch_size)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(trainloader, 0):\n",
    "        instances, labels = batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = baseline_model(instances)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "            running_loss = 0.0\n",
    "    val_acc = validate(baseline_model, testloader)\n",
    "    print(f'Epoch {epoch}, validation acc.: {val_acc}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Writing your own Elman RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be completed!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
